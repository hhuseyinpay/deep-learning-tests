{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T11:17:21.487948Z",
     "start_time": "2024-10-07T11:17:21.485733Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "678d04c7b86401f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T11:17:21.503528Z",
     "start_time": "2024-10-07T11:17:21.500761Z"
    }
   },
   "outputs": [],
   "source": [
    "# indirince bunu bi denerik\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5358442db68a638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T11:17:22.283950Z",
     "start_time": "2024-10-07T11:17:21.655910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Create Training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=all_transforms, download=True)\n",
    "\n",
    "# Create Testing dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=all_transforms, download=True)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b36f6f8fd4089fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T12:06:28.724436Z",
     "start_time": "2024-10-07T12:06:28.720126Z"
    }
   },
   "source": [
    "# Define the CNN model\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    " \n",
    "        self.fc1 = nn.Linear(16384, 128)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.act1(self.conv_layer1(x))\n",
    "        out = self.act2(self.conv_layer2(out))\n",
    "        out = self.drop1(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop2(self.act5(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "56f97a268af6e521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T12:12:30.570176Z",
     "start_time": "2024-10-07T12:06:29.275278Z"
    }
   },
   "source": [
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "model = ConvNeuralNet(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = None\n",
    "    t = time.time()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {}, Elapsed: {} '.format(epoch + 1, num_epochs, loss.item(),\n",
    "                                                                           100 * correct / total, time.time() - t))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.4866, Accuracy: 42.2, Elapsed: 18.286622047424316 \n",
      "Epoch [2/20], Loss: 1.3297, Accuracy: 50.74, Elapsed: 18.17188787460327 \n",
      "Epoch [3/20], Loss: 1.2245, Accuracy: 52.98, Elapsed: 18.082685232162476 \n",
      "Epoch [4/20], Loss: 1.2724, Accuracy: 55.3, Elapsed: 18.015759229660034 \n",
      "Epoch [5/20], Loss: 1.2128, Accuracy: 57.46, Elapsed: 18.01895809173584 \n",
      "Epoch [6/20], Loss: 1.2538, Accuracy: 58.74, Elapsed: 18.005617141723633 \n",
      "Epoch [7/20], Loss: 1.3215, Accuracy: 58.94, Elapsed: 18.008980989456177 \n",
      "Epoch [8/20], Loss: 0.9250, Accuracy: 58.86, Elapsed: 18.04648494720459 \n",
      "Epoch [9/20], Loss: 0.7841, Accuracy: 60.36, Elapsed: 17.984088897705078 \n",
      "Epoch [10/20], Loss: 1.0321, Accuracy: 60.64, Elapsed: 18.09227991104126 \n",
      "Epoch [11/20], Loss: 1.1158, Accuracy: 60.7, Elapsed: 18.091243028640747 \n",
      "Epoch [12/20], Loss: 0.7492, Accuracy: 60.52, Elapsed: 18.11512589454651 \n",
      "Epoch [13/20], Loss: 0.9666, Accuracy: 60.72, Elapsed: 18.11518883705139 \n",
      "Epoch [14/20], Loss: 1.0016, Accuracy: 60.92, Elapsed: 18.043601989746094 \n",
      "Epoch [15/20], Loss: 1.0420, Accuracy: 60.82, Elapsed: 18.03047490119934 \n",
      "Epoch [16/20], Loss: 0.8707, Accuracy: 60.58, Elapsed: 18.12303590774536 \n",
      "Epoch [17/20], Loss: 0.7431, Accuracy: 60.38, Elapsed: 17.997031927108765 \n",
      "Epoch [18/20], Loss: 0.8439, Accuracy: 61.26, Elapsed: 18.01063585281372 \n",
      "Epoch [19/20], Loss: 0.6785, Accuracy: 60.86, Elapsed: 17.996093034744263 \n",
      "Epoch [20/20], Loss: 0.7357, Accuracy: 61.24, Elapsed: 18.036105394363403 \n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b238fe4bd16f9d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T11:21:48.977832Z",
     "start_time": "2024-10-07T11:21:48.972985Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "only single target (not tuple) can be annotated (175963.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[26], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Epoch [1/20], Loss: 1.3973, Accuracy: 54.56, Elapsed: 15.385615825653076\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m only single target (not tuple) can be annotated\n"
     ]
    }
   ],
   "source": [
    "Epoch [1/20], Loss: 1.3613, Accuracy: 53.62, Elapsed: 15.32989501953125 \n",
    "Epoch [2/20], Loss: 0.8447, Accuracy: 63.2, Elapsed: 15.123994827270508 \n",
    "Epoch [3/20], Loss: 0.8678, Accuracy: 65.93, Elapsed: 15.185999870300293 \n",
    "Epoch [4/20], Loss: 0.8962, Accuracy: 68.71, Elapsed: 15.104533195495605 \n",
    "Epoch [5/20], Loss: 0.5207, Accuracy: 70.58, Elapsed: 15.10148310661316 \n",
    "Epoch [6/20], Loss: 0.6476, Accuracy: 70.49, Elapsed: 15.253604650497437 \n",
    "Epoch [7/20], Loss: 0.5595, Accuracy: 70.84, Elapsed: 15.609240055084229 \n",
    "Epoch [8/20], Loss: 0.5878, Accuracy: 70.2, Elapsed: 15.391446113586426 \n",
    "Epoch [9/20], Loss: 0.4980, Accuracy: 69.8, Elapsed: 15.125716209411621 \n",
    "Epoch [10/20], Loss: 0.2939, Accuracy: 69.97, Elapsed: 15.214236974716187 \n",
    "Epoch [11/20], Loss: 0.3107, Accuracy: 70.41, Elapsed: 15.064754962921143 \n",
    "Epoch [12/20], Loss: 0.3099, Accuracy: 70.17, Elapsed: 15.302250146865845 \n",
    "Epoch [13/20], Loss: 0.3888, Accuracy: 68.96, Elapsed: 15.270372152328491 \n",
    "Epoch [14/20], Loss: 0.3394, Accuracy: 69.54, Elapsed: 15.145703077316284 \n",
    "Epoch [15/20], Loss: 0.2791, Accuracy: 69.18, Elapsed: 15.143717050552368"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c1779b320b3b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
